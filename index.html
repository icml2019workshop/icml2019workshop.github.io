<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="NeurIPS 2018 Workshop on Security in Machine Learning">

  <title>Security and Privacy of Machine Learning</title>

  <!-- Bootstrap core CSS -->
  <link href="bootstrap.min.css" rel="stylesheet">
</head>

<body>

<!-- Begin page content -->
<main role="main" class="container">
  <h1 class="mt-5">Security and Privacy of Machine Learning
</h1>
  <p class="mb-0"><b>Date:</b> June, 2019</p>
  <p class="mb-0"><b>Location:</b> Long Beach, CA, USA (co-located with <a href="https://icml.cc/Conferences/2019/">ICML 2019</a>)</p>
  <!-- <p class="mb-0"><b>Contact:</b> xxx (this will email all organizers)</p> -->
  <p>
    <i>Abstract</i>—As machine learning has increasingly been deployed in critical real-world applications, the dangers of manipulation and misuse of these models has become of paramount importance to public safety and user privacy.  In applications such as online content recognition to financial analytics to autonomous vehicles all have shown the be vulnerable to adversaries wishing to manipulate the models or mislead models to their malicious ends.  
  </p>
  <p>
    This workshop will focus on recent research and future directions about the security and privacy problems in real-world machine learning systems. We aim to bring together experts from machine learning, security, and privacy communities in an attempt to highlight recent work in these area as well as to clarify the foundations of secure and private machine learning strategies. We seek to come to a consensus on a rigorous framework to formulate adversarial attacks targeting machine learning models, and to characterize the properties that ensure the security and privacy of machine learning systems. Finally, we hope to chart out important directions for future work and cross-community collaborations.
  </p>
  <!-- <h2>Sponsor</h2> -->
  <!-- <p></p> -->

  <h2>Schedule</h2>
  <p>The following is a tentative schedule and is subject to change prior to the workshop.</p>

  <table class="table table-sm">
    <tbody>
    <tr>
      <th scope="row">8:40am</th>
      <td>Opening Remarks</td>
      <td></td>
    </tr>

    <tr><th scope="row" colspan="3">Session 1:Adversarial attacks against machine learning models</th></tr>
    <tr>
      <th scope="row">9:00am</th>
      <td>Invited Talk #1: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">9:30am</th>
      <td>Contributed Talk #1: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">10:40am</th>
      <td>Poster Spotlights #1: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">10:00am</th>
      <td>Coffee Break </td>
    </tr>
    <tr><th scope="row" colspan="3">Session 2:Security and privacy problems in machine learning</th></tr>
    <tr>
      <th scope="row">10:30am</th>
      <td>Invited Talk #2: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">11:00am</th>
      <td>Contributed Talk #2: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">11:15am</th>
      <td>Invited Talk #3: </td>
      <td></td>
    <tr>
      <th scope="row">11:45am</th>
      <td>Poster Spotlights #2: </td>
      <td></td>
    </tr>
    </tr>
    <tr>
      <th scope="row">12:00pm</th>
      <td>Lunch </td>
    </tr>
    <tr><th scope="row" colspan="3">Session 3:Improve Model Robustness Against Adversarial Examples</th></tr>
    
    <tr>
      <th scope="row">1:15pm</th>
      <td>Invited Talk #4: </td>
      <td><a target="_blank"></a></td>
    </tr>
    <tr>
      <th scope="row">1:45pm</th>
      <td>Contributed Talk #3:</td>
      <td></td>
    </tr>


    <!-- <tr><th scope="row" colspan="3">2:00pm</th></tr> -->
    <tr>
      <th scope="row">2:00pm</th>
      <td>Poster Session followed by break</td>
      <td></td>
    </tr>

    <tr><th scope="row" colspan="3">Session 4: Provable robustness, and interpretable machine learning approaches
</th></tr>
    <tr>
      <th scope="row">2:45pm</th>
      <td>Invited Talk #5: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">3:15pm</th>
      <td>Contributed Talk #4: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">3:30pm</th>
      <td>Contributed Talk #5: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">3:45pm</th>
      <td>Contributed Talk #6: </td>
      <td></td>
    </tr>
     <tr>
      <th scope="row">4:00pm</th>
      <td>Contributed Talk #7: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">4:15pm</th>
      <td>Panel discussion </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">5:15pm</th>
      <td>Poster Sesson </td>
      <td></td>
    </tr>
    </tbody>
  </table>
 <!--  
<h2>Important Dates</h2>
<ul>
  <li>Workshop paper submission deadline: 5/10/2019</li>
  <li>Notification to authors: 6/01/2019</li>
  <li>Camera ready deadline: 6/12/2019</li>
</ul> -->

	


	
	


<h2>Call For Papers</h2>
  <p class="mb-0"><b>Submission deadline:</b> May 10, 2019 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Notification sent to authors:</b> June 1, 2019 Anywhere on Earth (AoE)</p>
  <!-- <p class="mb-0"><b>Submission server:</b> <a href="https://easychair.org/cfp/AdvMLCV2019" target="_blank">https://easychair.org/cfp/AdvMLCV2019</a></p> -->
	
  <p>The workshop will include contributed papers. Based on the PC’s recommendation, each paper accepted to the workshop will be allocated either a contributed talk or poster presentation .</p>
  <p>We invite submissions on <b>any aspect of machine learning that relates to computer security and privacy (and vice versa)</b>. This includes, but is not limited to:</p>

  <ul>
	  <li> Test-time (exploratory) attacks: e.g. adversarial examples for neural nets
    </li>
<li>Training-time (causative) attacks: e.g. data poisoning</li>
<li>Differential privacy</li>
<li>Privacy attacks</li>
<li>Stackelberg security games</li>
<li>Manipulation of crowd-sourcing systems</li>
<li>Sybil detection</li>
<li>Exploitable bugs in ML systems</li>
<li>Formal verification of ML systems</li>
<li>Model stealing</li>
<li>Misuse of AI and deep learning</li>
  </ul>

  <h2>Organizing Committee</h2>
  <div class="row justify-content-around">
    <!-- <div class="col-lg-1"></div> -->
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/boli.png" width="100px" height="100px">
      <p style="width:100px" >Bo Li<br /></p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/nicolas.jpg" width="100px" height="100px">
      <p style="width:140px" >Nicolas Papernot<br /> </p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/florian.jpg" width="100px" height="100px">
      <p style="width:120px" >Florian Tramer</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/jocob.png" width="100px" height="100px">
      <p style="width:150px" >Jocob Steinhardt</p>
    </div>
     <div class="col-md-1">
      <img class="rounded-circle" src="imgs/liang.jpg" width="100px" height="100px">
      <p style="width:100px" >Percy Liang</p>
    </div>
  </div>
    <div class="row justify-content-around">
     <div class="col-md-1">
      <img class="rounded-circle" src="imgs/david.jpg" width="100px" height="100px">
      <p style="width:100px" >David Evans</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/dawn.png" width="100px" height="100px">
      <p style="width:100px" >Dawn Song</p>
    </div>

    <!-- </div> -->
      <div class="col-md-1">
      <img class="rounded-circle" src="imgs/jha.jpg" width="100px" height="100px">
      <p style="width:100px" >Somesh Jha</p>
    </div>
      <div class="col-md-1">
      <img class="rounded-circle" src="imgs/dan.jpeg" width="100px" height="100px">
      <p style="width:100px" >Dan Boneh</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/patrick.png" width="100px" height="100px">
      <p style="width:150px" >Patrick McDaniel</p>
    </div>
  </div>
    <!-- <div class="col-lg-1"></div> -->
  </div>

<h2>Program Committee</h2>
<li>Bhavya Khailkhura (Lawrence Livermore National Lab)</li>
<li>Catherine Olsson (Google Brain)</li>
<li>Chaowei Xiao (University of Michigan)</li>
<li>David Evans (University of Virginia)</li>
<li>Dimitris Tsipras (Massachusetts Institute of Technology)</li>
<li>Earlence Fernandes (University of Washington)</li>
<li>Eric Wong (Carnegie Mellon University)</li>
<li>Fartash Faghri (University of Toronto)</li>
<li>Florian Tramer (Stanford University)</li>
<li>Hadi Abdullah (University of Florida)</li>
<li>Hao Su (UCSD)</li>
<li>Jonathan Uesato (DeepMind)</li>
<li>Karl Ni (In-Q-Tel)</li>
<li>Kassem Fawaz (University of Wisconsin-Madison)</li>
<li>Kathrin Grosse (CISPA)</li>
<li>Krishna Gummadi (MPI-SWS)</li>
<li>Matthew Wicker (University of Georgia)</li>
<li>Nathan Mundhenk (Lawrence Livermore National Lab)</li>
<li>Nicholas Carlini (Google Brain)</li>
<li>Nicolas Papernot (Google Brain and University of Toronto)</li>
<li>Octavian Suciu (University of Maryland)</li>
<li>Pin-Yu Chen (IBM)</li>
<li>Pushmeet Kohli (DeepMind)</li>
<li>Shreya Shankar (Stanford University)</li>
<li>Suman Jana (Columbia University)</li>
<li>Varun Chandrasekaran (University of Wisconsin-Madison)</li>
<li>Xiaowei Huang (Liverpool University)</li>
<li>Yanjun Qi (University of Virginia)</li>
<li>Yigitcan Kaya (University of Maryland)</li>
<li>Yizheng Chen (Georgia Tech)</li>

</body></html>
